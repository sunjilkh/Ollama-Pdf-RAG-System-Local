# ğŸ¤– Chat PDF RAG System

A **Retrieval-Augmented Generation (RAG)** system that allows you to chat with PDF documents using AI. Upload your PDFs, and the system will create a searchable knowledge base that you can query in natural language.

## ğŸŒŸ Features

- **ğŸ“„ PDF Processing**: Automatically load and process PDF documents
- **ğŸ” Intelligent Chunking**: Split documents into semantically meaningful chunks
- **ğŸ§  Vector Embeddings**: Create high-quality embeddings using Nomic Embed Text
- **ğŸ’¾ Persistent Storage**: Store embeddings in ChromaDB for fast retrieval
- **ğŸ¤– AI Chat Interface**: Interactive chat powered by Ollama LLMs
- **ğŸ§ª Comprehensive Testing**: Built-in testing suite for system validation
- **ğŸ“Š System Monitoring**: Real-time status and performance monitoring

## ğŸ—ï¸ System Architecture

```mermaid
graph TD
    A["ğŸ“„ PDF Documents"] --> B["ğŸ” Document Loader<br/>(loader.py)"]
    B --> C["âœ‚ï¸ Text Splitter<br/>(split.py)"]
    C --> D["ğŸ·ï¸ ID Assignment<br/>(assign_ids.py)"]
    D --> E["ğŸ§  Embedding Generation<br/>(embedding.py)"]
    E --> F["ğŸ’¾ Vector Database<br/>(ChromaDB)"]

    F --> G["ğŸ” Query Engine<br/>(query_database.py)"]
    G --> H["ğŸ¤– Ollama LLM<br/>(ollama_llm.py)"]
    H --> I["ğŸ’¬ Interactive Chat<br/>(main.py)"]

    J["ğŸ› ï¸ Database Creator<br/>(create_database.py)"] --> F
    K["ğŸ§ª RAG Tester<br/>(test_rag.py)"] --> F
    K --> H
```

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.8+**
- **Ollama** (for LLM functionality)
- **Git** (for cloning)

### Installation

1. **Clone the repository**

   ```bash
   git clone <your-repository-url>
   cd Chat_pdf_RAG_system
   ```

2. **Create and activate virtual environment**

   ```bash
   # On Windows
   python -m venv venv
   venv\Scripts\Activate.ps1

   # On macOS/Linux
   python -m venv venv
   source venv/bin/activate
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Install and setup Ollama**
   - Download from: https://ollama.ai/
   - Install required models:
   ```bash
   ollama pull nomic-embed-text  # For embeddings
   ollama pull llama2            # For chat (or any other model you prefer)
   ```

### Usage

1. **Add your PDF documents**

   - Place your PDF files in the project root directory

2. **Run the main system**

   ```bash
   python main.py
   ```

3. **Follow the interactive menu**:
   - **Option 1**: Check system status
   - **Option 2**: Process documents and create database
   - **Option 3**: Start interactive chat
   - **Option 4**: Test database queries
   - **Option 5**: Run system tests

## ğŸ“‹ Detailed Setup Instructions

### First Time Setup

1. **Process your documents** (Option 2 in main menu)

   - The system will automatically:
     - Load all PDF files from the current directory
     - Split them into optimized chunks
     - Generate embeddings
     - Create a searchable vector database

2. **Verify setup** (Option 4 in main menu)

   - Test the database with sample queries
   - Ensure all components are working correctly

3. **Start chatting** (Option 3 in main menu)
   - Ask questions about your documents
   - Get AI-powered answers with source citations

### System Requirements

- **Memory**: 4GB+ RAM recommended
- **Storage**: 2GB+ free space (for embeddings and models)
- **Network**: Internet connection for initial Ollama model downloads

## ğŸ§ª Testing

The system includes comprehensive testing:

```bash
# Run through main menu (Option 5)
python main.py

# Or run directly
python test_rag.py
```

Tests include:

- Database connectivity
- Embedding generation
- Query accuracy
- Response quality
- System integration

## ğŸ“ Project Structure

```
Chat_pdf_RAG_system/
â”œâ”€â”€ main.py                 # Main application runner
â”œâ”€â”€ loader.py              # PDF document loading
â”œâ”€â”€ split.py               # Document chunking
â”œâ”€â”€ assign_ids.py          # Unique ID assignment
â”œâ”€â”€ embedding.py           # Embedding generation
â”œâ”€â”€ create_database.py     # Vector database creation
â”œâ”€â”€ query_database.py      # Database querying
â”œâ”€â”€ ollama_llm.py          # LLM integration
â”œâ”€â”€ test_rag.py           # Testing suite
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ db/                   # Vector database storage
â””â”€â”€ venv/                 # Virtual environment
```

## ğŸ”§ Configuration

### Customizing Models

Edit the model configurations in:

- `embedding.py`: Change embedding model
- `ollama_llm.py`: Change chat LLM model

### Adjusting Chunk Size

Modify chunking parameters in `split.py`:

```python
chunk_size = 1000      # Characters per chunk
chunk_overlap = 200    # Overlap between chunks
```

## ğŸ› Troubleshooting

### Common Issues

1. **Ollama connection failed**

   - Ensure Ollama is installed and running
   - Check if required models are downloaded

2. **Database creation errors**

   - Verify PDF files are in the directory
   - Check available disk space
   - Ensure write permissions

3. **Import errors**

   - Verify virtual environment is activated
   - Reinstall requirements: `pip install -r requirements.txt`

4. **Memory issues**
   - Reduce chunk size in `split.py`
   - Process fewer documents at once

### Getting Help

1. Check system status (Option 1 in main menu)
2. Run system tests (Option 5 in main menu)
3. Review console output for specific error messages

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## ğŸ“„ License

This project is open source. Please check the license file for details.

## ğŸ”— Dependencies

- **langchain**: Framework for building AI applications
- **langchain-community**: Community integrations
- **langchain-ollama**: Ollama integration
- **langchain-chroma**: ChromaDB integration
- **chromadb**: Vector database
- **pypdf**: PDF processing
- **pytest**: Testing framework

## ğŸ†• Version History

- **v1.0**: Initial release with basic RAG functionality
- Current: Full-featured system with testing and monitoring

---

**Happy chatting with your PDFs! ğŸ‰**
