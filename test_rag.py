import json
import time
from datetime import datetime
from ollama_llm import run_rag_query, query_ollama, get_available_models
from query_database import load_database


class RAGTester:
    """Class to test and evaluate RAG system performance with mixed-language support."""

    def __init__(self, db=None):
        """Initialize RAG tester."""
        self.db = db or load_database()
        self.test_results = []

    def evaluate_answer_similarity(self, expected, actual, judge_model="phi3"):
        """
        Use LLM to judge if two answers are equivalent in meaning.
        Enhanced to handle mixed-language evaluation.

        Args:
            expected: Expected answer (English or Bangla)
            actual: Actual RAG system answer
            judge_model: Model to use for evaluation

        Returns:
            Tuple of (is_equivalent: bool, confidence: str, explanation: str)
        """
        judge_prompt = f"""
You are an expert evaluator for a multilingual RAG system. Compare these two answers and determine if they convey the same core information and meaning.

Expected Answer: "{expected}"

Actual Answer: "{actual}"

Evaluation Criteria:
- Do both answers address the same key concepts?
- Is the factual information consistent?
- Minor differences in wording are acceptable
- Focus on semantic equivalence, not exact word matching
- Both answers may be in different languages (English/Bangla) but should convey same meaning
- Consider cross-language consistency where applicable

Respond with ONLY this format:
EQUIVALENT: [TRUE/FALSE]
CONFIDENCE: [HIGH/MEDIUM/LOW]
EXPLANATION: [Brief explanation of your judgment]
"""

        try:
            response = query_ollama(
                judge_prompt, model=judge_model, max_tokens=200, temperature=0.1
            )

            if not response:
                return False, "LOW", "Failed to get evaluation from judge model"

            # Parse response
            lines = response.strip().split("\n")
            equivalent = False
            confidence = "LOW"
            explanation = "Could not parse evaluation"

            for line in lines:
                if line.startswith("EQUIVALENT:"):
                    equivalent = "TRUE" in line.upper()
                elif line.startswith("CONFIDENCE:"):
                    confidence = line.split(":", 1)[1].strip()
                elif line.startswith("EXPLANATION:"):
                    explanation = line.split(":", 1)[1].strip()

            return equivalent, confidence, explanation

        except Exception as e:
            return False, "LOW", f"Error in evaluation: {e}"

    def test_single_question(
        self, question, expected_answer, test_id=None, language="auto"
    ):
        """
        Test a single question and evaluate the result.
        Enhanced with language detection and mixed-language support.

        Args:
            question: Question to ask
            expected_answer: Expected answer for comparison
            test_id: Optional test identifier
            language: Language of the question (auto, english, bangla)

        Returns:
            Dictionary with test results
        """
        print(f"\nüß™ Testing ({language}): {question}")

        start_time = time.time()

        # Get RAG response
        rag_result = run_rag_query(question, db=self.db, k=3)

        end_time = time.time()
        response_time = end_time - start_time

        if not rag_result["success"]:
            return {
                "test_id": test_id,
                "question": question,
                "expected_answer": expected_answer,
                "actual_answer": rag_result["answer"],
                "success": False,
                "equivalent": False,
                "confidence": "N/A",
                "explanation": "RAG query failed",
                "response_time": response_time,
                "sources_found": 0,
                "model_used": None,
                "language": language,
            }

        # Evaluate answer quality
        equivalent, confidence, explanation = self.evaluate_answer_similarity(
            expected_answer, rag_result["answer"]
        )

        result = {
            "test_id": test_id,
            "question": question,
            "expected_answer": expected_answer,
            "actual_answer": rag_result["answer"],
            "success": rag_result["success"],
            "equivalent": equivalent,
            "confidence": confidence,
            "explanation": explanation,
            "response_time": response_time,
            "sources_found": rag_result.get("num_sources", 0),
            "model_used": rag_result.get("model_used"),
            "source_pages": [s["page"] for s in rag_result.get("sources", [])],
            "language": language,
        }

        # Print results
        status = "‚úÖ PASS" if equivalent else "‚ùå FAIL"
        print(f"{status} - Equivalent: {equivalent} (Confidence: {confidence})")
        print(f"Response time: {response_time:.2f}s")
        print(
            f"Sources: {result['sources_found']} chunks from pages {result['source_pages']}"
        )

        return result

    def run_test_suite(self):
        """Run comprehensive test suite with various question types in English and Bangla."""

        test_cases = [
            # === ENGLISH ALGORITHM QUESTIONS ===
            {
                "id": "algo_001_en",
                "question": "What is an algorithm?",
                "expected": "A finite sequence of instructions for solving a problem or computational procedure",
                "language": "english",
            },
            {
                "id": "sort_001_en",
                "question": "How does merge sort work?",
                "expected": "Merge sort divides array into halves, recursively sorts them, then merges sorted halves",
                "language": "english",
            },
            {
                "id": "complexity_001_en",
                "question": "What is the time complexity of quicksort?",
                "expected": "Average case O(n log n), worst case O(n¬≤)",
                "language": "english",
            },
            {
                "id": "ds_001_en",
                "question": "What is a binary search tree?",
                "expected": "A binary tree where left subtree values are less than node, right subtree values are greater",
                "language": "english",
            },
            {
                "id": "dp_001_en",
                "question": "What is dynamic programming?",
                "expected": "An algorithmic technique that solves problems by breaking them into overlapping subproblems",
                "language": "english",
            },
            # === BANGLA ALGORITHM QUESTIONS ===
            {
                "id": "algo_001_bn",
                "question": "‡¶Ö‡ßç‡¶Ø‡¶æ‡¶≤‡¶ó‡¶∞‡¶ø‡¶¶‡¶Æ ‡¶ï‡¶ø?",
                "expected": "‡¶Ö‡ßç‡¶Ø‡¶æ‡¶≤‡¶ó‡¶∞‡¶ø‡¶¶‡¶Æ ‡¶π‡¶≤ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶®‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶æ‡¶¨‡¶≤‡ßÄ‡¶∞ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ï‡ßç‡¶∞‡¶Æ",
                "language": "bangla",
            },
            {
                "id": "sort_001_bn",
                "question": "‡¶Æ‡¶æ‡¶∞‡ßç‡¶ú ‡¶∏‡¶∞‡ßç‡¶ü ‡¶ï‡¶ø‡¶≠‡¶æ‡¶¨‡ßá ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡ßá?",
                "expected": "‡¶Æ‡¶æ‡¶∞‡ßç‡¶ú ‡¶∏‡¶∞‡ßç‡¶ü ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶∞‡ßá‡¶ï‡ßá ‡¶Ö‡¶Ç‡¶∂‡ßá ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡ßá, ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶Ö‡¶Ç‡¶∂ ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ‡¶≠‡¶æ‡¶¨‡ßá ‡¶∏‡¶æ‡¶ú‡¶æ‡¶Ø‡¶º, ‡¶§‡¶æ‡¶∞‡¶™‡¶∞ ‡¶∏‡ßá‡¶ó‡ßÅ‡¶≤‡ßã ‡¶è‡¶ï‡¶§‡ßç‡¶∞‡¶ø‡¶§ ‡¶ï‡¶∞‡ßá",
                "language": "bangla",
            },
            {
                "id": "complexity_001_bn",
                "question": "‡¶ï‡ßÅ‡¶á‡¶ï‡¶∏‡¶∞‡ßç‡¶ü‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ú‡¶ü‡¶ø‡¶≤‡¶§‡¶æ ‡¶ï‡¶§?",
                "expected": "‡¶ó‡¶°‡¶º ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡¶∞‡ßá O(n log n), ‡¶∏‡¶¨‡¶ö‡ßá‡¶Ø‡¶º‡ßá ‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™ ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡¶∞‡ßá O(n¬≤)",
                "language": "bangla",
            },
            {
                "id": "ds_001_bn",
                "question": "‡¶¨‡¶æ‡¶á‡¶®‡¶æ‡¶∞‡¶ø ‡¶∏‡¶æ‡¶∞‡ßç‡¶ö ‡¶ü‡ßç‡¶∞‡¶ø ‡¶ï‡¶ø?",
                "expected": "‡¶è‡¶ï‡¶ü‡¶ø ‡¶¨‡¶æ‡¶á‡¶®‡¶æ‡¶∞‡¶ø ‡¶ü‡ßç‡¶∞‡¶ø ‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá ‡¶¨‡¶æ‡¶Æ ‡¶∏‡¶æ‡¶¨‡¶ü‡ßç‡¶∞‡¶ø‡¶§‡ßá ‡¶õ‡ßã‡¶ü ‡¶Æ‡¶æ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶°‡¶æ‡¶® ‡¶∏‡¶æ‡¶¨‡¶ü‡ßç‡¶∞‡¶ø‡¶§‡ßá ‡¶¨‡¶°‡¶º ‡¶Æ‡¶æ‡¶® ‡¶•‡¶æ‡¶ï‡ßá",
                "language": "bangla",
            },
            {
                "id": "dp_001_bn",
                "question": "‡¶°‡¶æ‡¶á‡¶®‡¶æ‡¶Æ‡¶ø‡¶ï ‡¶™‡ßç‡¶∞‡ßã‡¶ó‡ßç‡¶∞‡¶æ‡¶Æ‡¶ø‡¶Ç ‡¶ï‡¶ø?",
                "expected": "‡¶è‡¶ï‡¶ü‡¶ø ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶≤‡¶ó‡¶∞‡¶ø‡¶¶‡¶Æ‡¶ø‡¶ï ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø ‡¶Ø‡¶æ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ‡¶ï‡ßá ‡¶õ‡ßã‡¶ü ‡¶â‡¶™-‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡ßá ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡ßá",
                "language": "bangla",
            },
            # === MIXED LANGUAGE TEXTBOOK QUESTIONS ===
            {
                "id": "textbook_001_en",
                "question": "What is asymptotic notation?",
                "expected": "Mathematical notation used to describe the limiting behavior of functions, commonly used for algorithm analysis",
                "language": "english",
            },
            {
                "id": "textbook_001_bn",
                "question": "‡¶Ö‡ßç‡¶Ø‡¶æ‡¶∏‡¶ø‡¶Æ‡ßç‡¶™‡¶ü‡ßã‡¶ü‡¶ø‡¶ï ‡¶®‡ßã‡¶ü‡ßá‡¶∂‡¶® ‡¶ï‡¶ø?",
                "expected": "‡¶´‡¶æ‡¶Ç‡¶∂‡¶®‡ßá‡¶∞ ‡¶∏‡ßÄ‡¶Æ‡¶æ‡¶¨‡¶¶‡ßç‡¶ß‡¶§‡¶æ ‡¶¨‡¶∞‡ßç‡¶£‡¶®‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡ßÉ‡¶§ ‡¶ó‡¶æ‡¶£‡¶ø‡¶§‡¶ø‡¶ï ‡¶®‡ßã‡¶ü‡ßá‡¶∂‡¶® ‡¶Ø‡¶æ ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶≤‡¶ó‡¶∞‡¶ø‡¶¶‡¶Æ ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£‡ßá ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡ßÉ‡¶§ ‡¶π‡¶Ø‡¶º",
                "language": "bangla",
            },
            {
                "id": "heap_001_en",
                "question": "How do you maintain the heap property?",
                "expected": "Use heapify operations to ensure parent nodes satisfy heap property relative to children",
                "language": "english",
            },
            {
                "id": "heap_001_bn",
                "question": "‡¶π‡¶ø‡¶™ ‡¶™‡ßç‡¶∞‡¶™‡¶æ‡¶∞‡ßç‡¶ü‡¶ø ‡¶ï‡¶ø‡¶≠‡¶æ‡¶¨‡ßá ‡¶¨‡¶ú‡¶æ‡¶Ø‡¶º ‡¶∞‡¶æ‡¶ñ‡¶æ ‡¶π‡¶Ø‡¶º?",
                "expected": "‡¶π‡¶ø‡¶™‡¶ø‡¶´‡¶æ‡¶á ‡¶Ö‡¶™‡¶æ‡¶∞‡ßá‡¶∂‡¶® ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶™‡ßç‡¶Ø‡¶æ‡¶∞‡ßá‡¶®‡ßç‡¶ü ‡¶®‡ßã‡¶° ‡¶è‡¶¨‡¶Ç ‡¶ö‡¶æ‡¶á‡¶≤‡ßç‡¶° ‡¶®‡ßã‡¶°‡ßá‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶π‡¶ø‡¶™ ‡¶™‡ßç‡¶∞‡¶™‡¶æ‡¶∞‡ßç‡¶ü‡¶ø ‡¶¨‡¶ú‡¶æ‡¶Ø‡¶º ‡¶∞‡¶æ‡¶ñ‡¶æ ‡¶π‡¶Ø‡¶º",
                "language": "bangla",
            },
            {
                "id": "graph_001_en",
                "question": "What is Dijkstra's algorithm used for?",
                "expected": "Finding shortest paths from a source vertex to all other vertices in weighted graphs",
                "language": "english",
            },
            {
                "id": "graph_001_bn",
                "question": "‡¶°‡¶æ‡¶á‡¶ú‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶æ‡¶∞ ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶≤‡¶ó‡¶∞‡¶ø‡¶¶‡¶Æ ‡¶ï‡¶ø ‡¶ú‡¶®‡ßç‡¶Ø ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡ßÉ‡¶§ ‡¶π‡¶Ø‡¶º?",
                "expected": "‡¶ì‡¶ú‡¶®‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§ ‡¶ó‡ßç‡¶∞‡¶æ‡¶´‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶â‡ßé‡¶∏ ‡¶•‡ßá‡¶ï‡ßá ‡¶Ö‡¶®‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶Ø ‡¶∏‡¶¨ ‡¶∂‡ßÄ‡¶∞‡ßç‡¶∑‡ßá ‡¶∏‡¶¨‡¶ö‡ßá‡¶Ø‡¶º‡ßá ‡¶õ‡ßã‡¶ü ‡¶™‡¶• ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø",
                "language": "bangla",
            },
            # === ADVANCED TEXTBOOK CONCEPTS ===
            {
                "id": "advanced_001_en",
                "question": "What is the master theorem?",
                "expected": "A method for solving recurrence relations commonly found in divide-and-conquer algorithms",
                "language": "english",
            },
            {
                "id": "advanced_001_bn",
                "question": "‡¶Æ‡¶æ‡¶∏‡ßç‡¶ü‡¶æ‡¶∞ ‡¶•‡¶ø‡¶ì‡¶∞‡ßá‡¶Æ ‡¶ï‡¶ø?",
                "expected": "‡¶°‡¶ø‡¶≠‡¶æ‡¶á‡¶° ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶° ‡¶ï‡¶®‡¶ï‡¶æ‡¶∞ ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶≤‡¶ó‡¶∞‡¶ø‡¶¶‡¶Æ‡ßá ‡¶™‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶∞‡¶ø‡¶ï‡¶æ‡¶∞‡ßá‡¶®‡ßç‡¶∏ ‡¶∞‡¶ø‡¶≤‡ßá‡¶∂‡¶® ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶®‡ßá‡¶∞ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø",
                "language": "bangla",
            },
            {
                "id": "complexity_002_en",
                "question": "What is NP-completeness?",
                "expected": "A class of computational problems that are among the most difficult problems in NP",
                "language": "english",
            },
            {
                "id": "complexity_002_bn",
                "question": "NP-completeness ‡¶ï‡¶ø?",
                "expected": "NP-‡¶§‡ßá ‡¶∏‡¶¨‡¶ö‡ßá‡¶Ø‡¶º‡ßá ‡¶ï‡¶†‡¶ø‡¶® ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ‡¶ó‡ßÅ‡¶≤‡ßã‡¶∞ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∂‡ßç‡¶∞‡ßá‡¶£‡¶ø ‡¶Ø‡¶æ ‡¶ó‡¶£‡¶®‡¶æ‡¶ó‡¶§ ‡¶ú‡¶ü‡¶ø‡¶≤‡¶§‡¶æ‡¶∞ ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡¶∞‡ßá ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£",
                "language": "bangla",
            },
            # === NEGATIVE TEST CASES ===
            {
                "id": "negative_001_en",
                "question": "How do I cook pasta?",
                "expected": "No relevant information found",
                "language": "english",
            },
            {
                "id": "negative_001_bn",
                "question": "‡¶Ü‡¶Æ‡¶ø ‡¶ï‡¶ø‡¶≠‡¶æ‡¶¨‡ßá ‡¶™‡¶æ‡¶∏‡ßç‡¶§‡¶æ ‡¶∞‡¶æ‡¶®‡ßç‡¶®‡¶æ ‡¶ï‡¶∞‡¶¨?",
                "expected": "‡¶ï‡ßã‡¶® ‡¶™‡ßç‡¶∞‡¶æ‡¶∏‡¶ô‡ßç‡¶ó‡¶ø‡¶ï ‡¶§‡¶•‡ßç‡¶Ø ‡¶™‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º‡¶®‡¶ø",
                "language": "bangla",
            },
            {
                "id": "negative_002_en",
                "question": "What is the weather today?",
                "expected": "No relevant information found",
                "language": "english",
            },
        ]

        print("üöÄ Starting BanglaRAG System Test Suite")
        print(f"üìä Running {len(test_cases)} test cases...")
        print("üåê Testing English & Bangla queries")
        print("üìö Evaluating textbook content comprehension")
        print("=" * 60)

        results = []

        for test_case in test_cases:
            result = self.test_single_question(
                test_case["question"],
                test_case["expected"],
                test_case["id"],
                test_case["language"],
            )
            results.append(result)
            time.sleep(1)  # Brief pause between tests

        self.test_results = results
        return results

    def generate_test_report(self, save_to_file=True):
        """Generate comprehensive test report with language-specific metrics."""
        if not self.test_results:
            print("No test results to report. Run test suite first.")
            return

        # Calculate overall statistics
        total_tests = len(self.test_results)
        passed_tests = sum(1 for r in self.test_results if r["equivalent"])
        failed_tests = total_tests - passed_tests
        pass_rate = (passed_tests / total_tests) * 100

        avg_response_time = (
            sum(r["response_time"] for r in self.test_results) / total_tests
        )

        # Calculate language-specific statistics
        english_tests = [r for r in self.test_results if r["language"] == "english"]
        bangla_tests = [r for r in self.test_results if r["language"] == "bangla"]

        english_passed = sum(1 for r in english_tests if r["equivalent"])
        bangla_passed = sum(1 for r in bangla_tests if r["equivalent"])

        english_pass_rate = (
            (english_passed / len(english_tests)) * 100 if english_tests else 0
        )
        bangla_pass_rate = (
            (bangla_passed / len(bangla_tests)) * 100 if bangla_tests else 0
        )

        # Calculate confidence distribution
        confidence_counts = {"HIGH": 0, "MEDIUM": 0, "LOW": 0}
        for result in self.test_results:
            if result["equivalent"]:
                confidence_counts[result["confidence"]] += 1

        # Generate report
        report = {
            "test_summary": {
                "timestamp": datetime.now().isoformat(),
                "total_tests": total_tests,
                "passed": passed_tests,
                "failed": failed_tests,
                "pass_rate": round(pass_rate, 2),
                "average_response_time": round(avg_response_time, 2),
                "language_breakdown": {
                    "english": {
                        "total": len(english_tests),
                        "passed": english_passed,
                        "pass_rate": round(english_pass_rate, 2),
                    },
                    "bangla": {
                        "total": len(bangla_tests),
                        "passed": bangla_passed,
                        "pass_rate": round(bangla_pass_rate, 2),
                    },
                },
                "confidence_distribution": confidence_counts,
            },
            "detailed_results": self.test_results,
        }

        # Print summary
        print("\n" + "=" * 60)
        print("üìã BANGLARAG SYSTEM TEST REPORT")
        print("=" * 60)
        print(f"üìä OVERALL RESULTS:")
        print(f"   Total Tests: {total_tests}")
        print(f"   Passed: {passed_tests}")
        print(f"   Failed: {failed_tests}")
        print(f"   Pass Rate: {pass_rate:.1f}%")
        print(f"   Avg Response Time: {avg_response_time:.2f}s")

        print(f"\nüåê LANGUAGE-SPECIFIC RESULTS:")
        print(
            f"   English: {english_passed}/{len(english_tests)} ({english_pass_rate:.1f}%)"
        )
        print(
            f"   Bangla: {bangla_passed}/{len(bangla_tests)} ({bangla_pass_rate:.1f}%)"
        )

        print(f"\nüìà CONFIDENCE DISTRIBUTION:")
        for conf, count in confidence_counts.items():
            print(f"   {conf}: {count} tests")

        # Show failed tests
        failed_results = [r for r in self.test_results if not r["equivalent"]]
        if failed_results:
            print(f"\n‚ùå Failed Tests ({len(failed_results)}):")
            for result in failed_results:
                lang_flag = {"english": "üá∫üá∏", "bangla": "üáßüá©"}.get(
                    result["language"], "üåê"
                )
                print(f"  {lang_flag} {result['test_id']}: {result['question']}")
                print(f"    Reason: {result['explanation']}")

        # Show passed tests
        passed_results = [r for r in self.test_results if r["equivalent"]]
        if passed_results:
            print(f"\n‚úÖ Passed Tests ({len(passed_results)}):")
            for result in passed_results:
                confidence_emoji = {"HIGH": "üü¢", "MEDIUM": "üü°", "LOW": "üî¥"}.get(
                    result["confidence"], "‚ö™"
                )
                lang_flag = {"english": "üá∫üá∏", "bangla": "üáßüá©"}.get(
                    result["language"], "üåê"
                )
                print(
                    f"  {lang_flag} {result['test_id']}: {result['question']} {confidence_emoji}"
                )

        # Save to file
        if save_to_file:
            filename = (
                f"banglarag_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            )
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            print(f"\nüíæ Detailed report saved to: {filename}")

        print("=" * 60)

        return report


def run_quick_test():
    """Run a quick test with a few questions."""
    print("üèÉ‚Äç‚ôÇÔ∏è Running Quick RAG Test...")

    # Check if database exists
    db = load_database()
    if not db:
        print("‚ùå Database not found. Please run create_database.py first.")
        return

    # Check if Ollama is available
    models = get_available_models()
    if not models:
        print("‚ùå No Ollama models available. Please install a model: ollama pull phi3")
        return

    # Initialize tester
    tester = RAGTester(db)

    # Test a few questions
    quick_tests = [
        (
            "What is an algorithm?",
            "A procedure or set of instructions for solving a problem",
        ),
        (
            "How does quicksort work?",
            "Divides array using pivot, recursively sorts partitions",
        ),
        ("What is machine learning?", "No relevant information found"),  # Should fail
    ]

    results = []
    for question, expected in quick_tests:
        result = tester.test_single_question(question, expected)
        results.append(result)

    # Quick summary
    passed = sum(1 for r in results if r["equivalent"])
    print(f"\nüìä Quick Test Results: {passed}/{len(results)} passed")

    return results


def run_bangla_quick_test():
    """Run a quick test with mixed English and Bangla questions."""
    print("üèÉ‚Äç‚ôÇÔ∏è Running Quick BanglaRAG Test...")

    # Check if database exists
    db = load_database()
    if not db:
        print("‚ùå Database not found. Please run create_database.py first.")
        return

    # Check if Ollama is available
    models = get_available_models()
    if not models:
        print("‚ùå No Ollama models available. Please install a model: ollama pull phi3")
        return

    # Initialize tester
    tester = RAGTester(db)

    # Test mixed language questions
    quick_tests = [
        (
            "What is an algorithm?",
            "A procedure or set of instructions for solving a problem",
            "english",
        ),
        (
            "‡¶Ö‡ßç‡¶Ø‡¶æ‡¶≤‡¶ó‡¶∞‡¶ø‡¶¶‡¶Æ ‡¶ï‡¶ø?",
            "‡¶Ö‡ßç‡¶Ø‡¶æ‡¶≤‡¶ó‡¶∞‡¶ø‡¶¶‡¶Æ ‡¶π‡¶≤ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶®‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶æ‡¶¨‡¶≤‡ßÄ‡¶∞ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ï‡ßç‡¶∞‡¶Æ",
            "bangla",
        ),
        (
            "How does quicksort work?",
            "Divides array using pivot, recursively sorts partitions",
            "english",
        ),
        (
            "‡¶ï‡ßÅ‡¶á‡¶ï‡¶∏‡¶∞‡ßç‡¶ü‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ú‡¶ü‡¶ø‡¶≤‡¶§‡¶æ ‡¶ï‡¶§?",
            "‡¶ó‡¶°‡¶º ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡¶∞‡ßá O(n log n), ‡¶∏‡¶¨‡¶ö‡ßá‡¶Ø‡¶º‡ßá ‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™ ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡¶∞‡ßá O(n¬≤)",
            "bangla",
        ),
        (
            "What is machine learning?",
            "No relevant information found",
            "english",
        ),  # Should fail
    ]

    results = []
    for question, expected, language in quick_tests:
        result = tester.test_single_question(question, expected, language=language)
        results.append(result)

    # Quick summary
    passed = sum(1 for r in results if r["equivalent"])
    english_passed = sum(
        1 for r in results if r["language"] == "english" and r["equivalent"]
    )
    bangla_passed = sum(
        1 for r in results if r["language"] == "bangla" and r["equivalent"]
    )

    print(f"\nüìä Quick Test Results:")
    print(f"   Overall: {passed}/{len(results)} passed")
    print(
        f"   English: {english_passed}/{sum(1 for r in results if r['language'] == 'english')} passed"
    )
    print(
        f"   Bangla: {bangla_passed}/{sum(1 for r in results if r['language'] == 'bangla')} passed"
    )

    return results


if __name__ == "__main__":
    print("üß™ BanglaRAG System Testing Framework")
    print("Choose test mode:")
    print("1. Quick test (5 mixed-language questions)")
    print("2. Full test suite (20+ mixed-language questions)")
    print("3. Original quick test (3 English questions)")

    choice = input("Enter choice (1, 2, or 3): ").strip()

    if choice == "1":
        run_bangla_quick_test()
    elif choice == "2":
        # Full test suite
        db = load_database()
        if not db:
            print("‚ùå Database not found. Please run create_database.py first.")
        else:
            tester = RAGTester(db)
            tester.run_test_suite()
            tester.generate_test_report()
    elif choice == "3":
        run_quick_test()
    else:
        print("Invalid choice. Running Bangla quick test...")
        run_bangla_quick_test()
